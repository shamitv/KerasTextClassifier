{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-13 22:03:07,973 - Yelp_Review_Processor - INFO - Looking for data :: G:\\work\\nlp\\datasets\\yelp\\attention\\dataset\\yelp_review_binary_processed.npz\n",
      "2018-07-13 22:03:07,975 - Yelp_Review_Processor - INFO - Loading data from cache\n",
      "2018-07-13 22:03:10,767 - Yelp_Review_Processor - INFO - Loaded data in cache\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from yelp_sentiment_attention.train import *\n",
    "from yelp_multiclass.data.yelp_dataset import load_word_indices\n",
    "\n",
    "from yelp_multiclass.data.textProcess import createTextSent,tokenizeText,buildIndexToWordDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore trained model from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-13 22:03:12,443 - Yelp_Review_Processor - INFO - Restorng saved model\n",
      "INFO:tensorflow:Restoring parameters from G:\\work\\nlp\\datasets\\yelp\\attention\\model\\\n",
      "2018-07-13 22:03:13,208 - tensorflow - INFO - Restoring parameters from G:\\work\\nlp\\datasets\\yelp\\attention\\model\\\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "log.info('Restorng saved model')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, MODEL_PATH)\n",
    "    x_batch_test, y_batch_test = X_test[:550], y_test[:550]\n",
    "    seq_len_test = np.array([list(x).index(0) + 1 for x in x_batch_test])\n",
    "    results = sess.run([alphas,y_hat], feed_dict={batch_ph: x_batch_test, target_ph: y_batch_test,\n",
    "                                                seq_len_ph: seq_len_test, keep_prob_ph: 1.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Vocab from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-13 22:03:28,414 - Yelp_Review_Processor - INFO - Reading Vocab\n",
      "2018-07-13 22:03:30,095 - Yelp_Review_Processor - INFO - Done\n"
     ]
    }
   ],
   "source": [
    "log.info('Reading Vocab')\n",
    "word_index = load_word_indices()\n",
    "index_word = buildIndexToWordDict(word_index)\n",
    "log.info('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read results from model and generate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working director is K:\\python_projects\\KerasTextClassifier\\yelp_sentiment_attention\\test\n"
     ]
    }
   ],
   "source": [
    "alphas_values = results[0][0]\n",
    "filename=\"visualization2.html\"\n",
    "with open(filename, \"w\") as html_file:\n",
    "    for X,alpha_values,Y_hat,Y in zip(x_batch_test,results[0],results[1],y_batch_test ) :\n",
    "        html_file.write(\"<br/><hr/>\");\n",
    "        sample = [x - 1 for x in X]\n",
    "        sample[0] = 1\n",
    "        sample=[0 if x == -1 else x for x in sample]\n",
    "        words = list(map(index_word.get, sample))\n",
    "        html_file.write('%s  %s\\n' % (Y, Y_hat));\n",
    "        if Y_hat > 0:\n",
    "            div_color='#b8efc8'\n",
    "        else:\n",
    "            div_color = '#ff848a'\n",
    "        html_file.write('<div style=\"background-color:%s\">\\n' % div_color);\n",
    "        for word, alpha in zip(words, alphas_values / alphas_values.max()):\n",
    "            if word == \":START:\":\n",
    "                continue\n",
    "            elif word == \":PAD:\":\n",
    "                break\n",
    "            html_file.write('<font style=\"background: rgba(255, 255, 0, %f)\">%s</font>\\n' % (alpha, word))\n",
    "        html_file.write('</div>\\n');\n",
    "print('Working director is ' +  os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
